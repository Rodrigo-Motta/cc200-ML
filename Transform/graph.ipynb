{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5c0a04-5483-4caa-a068-9e06fc2c63c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(rc={'image.cmap': 'coolwarm'})\n",
    "\n",
    "#from numba import jit,prange\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca6cf18-d292-4c44-a147-65c77b9aba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(size, corr):\n",
    "    corr_matrix = np.zeros((size,size))\n",
    "    cont = 0\n",
    "\n",
    "    for i in range(size):\n",
    "        for j in range(i, size):\n",
    "            if i == j:\n",
    "                corr_matrix[i,j] = float('nan')\n",
    "\n",
    "\n",
    "            else:\n",
    "                corr_matrix[i,j] = corr[cont]\n",
    "                corr_matrix[j,i] = corr[cont]\n",
    "                cont += 1 \n",
    "    return corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d0bc9e-d442-479e-a12c-e6e068f5b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(fisher):\n",
    "    if fisher == True:\n",
    "        df = pd.read_csv(r'/Users/rodrigo/Post-Grad/CC400/corr_matrices_fisher200.csv',index_col=['Institution','Subject'])\n",
    "        phenotypic = pd.read_csv(r'/Users/rodrigo/Post-Grad/CC400/phenotypic200.csv',index_col=['Institution','Subject'])\n",
    "    else:\n",
    "        df = pd.read_csv(r'/Users/rodrigo/Post-Grad/CC400/corr_matrices200.csv',index_col=['Institution','Subject','Run'])\n",
    "        phenotypic = pd.read_csv(r'/Users/rodrigo/Post-Grad/CC400/phenotypic200.csv',index_col=['Institution','Subject'])\n",
    "    return df,phenotypic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12920c28-3874-464b-acd6-2da7c2303fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, phenotypic = import_data(fisher=True)\n",
    "df = df.join(pd.DataFrame(phenotypic.Age), how='left')\n",
    "df = df.join(pd.DataFrame(phenotypic['ADHD Measure']), how='left')\n",
    "df = df.join(pd.DataFrame(phenotypic['Gender']), how='left')\n",
    "\n",
    "#df = ((df.reset_index()).drop(columns=['Institution', 'Subject','Run'])).dropna(subset=[str(x) for x in range(0,61425)])\n",
    "df = ((df.reset_index()).drop(columns=['Institution', 'Subject'])).dropna(subset=[str(x) for x in range(0,17954)])\n",
    "y = df.Gender\n",
    "X = df.iloc[:,:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa9f44a-0853-4384-b984-6b46a357cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae6545f-ae73-4e9a-9521-c84e193aad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "\n",
    "for i in range((X_train.shape[0])):\n",
    "    adj = torch.from_numpy(correlation_matrix(190,X.iloc[i,:].values)).float()\n",
    "    edge_index, edge_attr = dense_to_sparse(adj)\n",
    "    train_data.append(Data(x=adj, edge_index=edge_index, edge_attr=edge_attr, y=y.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15423ce4-45b9-42d4-8a3c-94e39c72ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "\n",
    "for i in range((X_test.shape[0])):\n",
    "    adj = torch.from_numpy(correlation_matrix(190,X.iloc[i,:].values)).float()\n",
    "    edge_index, edge_attr = dense_to_sparse(adj)\n",
    "    test_data.append(Data(x=adj, edge_index=edge_index, edge_attr=edge_attr, y=y.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49767bb6-2c5f-4180-9165-f9d046ad7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07d45df4-28f8-4a4f-9b24-0449e9c2b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 6080\n",
      "torch.Size([6080, 190])\n",
      "num_graphs 32\n",
      "num_nodes 570\n",
      "torch.Size([570, 190])\n",
      "num_graphs 3\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print('num_nodes',data.num_nodes)\n",
    "    print(data.x.shape)\n",
    "    #print(data.edge_index.shape)\n",
    "    #print(data.batch)\n",
    "    #print(data.y)\n",
    "    print('num_graphs', data.num_graphs)\n",
    "    # data = data.to(device)\n",
    "    # optimizer.zero_grad()\n",
    "    # out = model(data.x, data.edge_index, data.batch)\n",
    "    # loss = F.cross_entropy(out, data.y)\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    # total_loss += float(loss) * data.num_graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c89df864-e874-4177-9a0c-094ddd99da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as func\n",
    "from torch_geometric.nn import ChebConv, global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"GCN model(network architecture can be modified)\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_features,\n",
    "                 num_classes,\n",
    "                 k_order,\n",
    "                 dropout=.3):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.p = dropout\n",
    "\n",
    "        self.conv1 = ChebConv(int(num_features), 128, K=k_order)\n",
    "        self.conv2 = ChebConv(128, 64, K=k_order)\n",
    "        self.conv3 = ChebConv(64, 32, K=k_order)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(32, int(num_classes))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        batch = data.batch\n",
    "        \n",
    "        x = func.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = func.dropout(x, p=self.p, training=self.training)\n",
    "        x = func.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = func.dropout(x, p=self.p, training=self.training)\n",
    "        x = func.relu(self.conv3(x, edge_index, edge_attr))\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5a0663c-15ee-45f9-970a-3a4e53041501",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (190x190 and 36100x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m min_v_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf    \n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m---> 44\u001b[0m     t_loss \u001b[38;5;241m=\u001b[39m \u001b[43mGCN_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     test_sen, test_spe, test_acc, _ \u001b[38;5;241m=\u001b[39m GCN_test(test_loader)\n",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36mGCN_train\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mcross_entropy(output, data\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/GCN_study/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[11], line 28\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     25\u001b[0m x, edge_index, edge_attr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[1;32m     26\u001b[0m batch \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mbatch\n\u001b[0;32m---> 28\u001b[0m x \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index, edge_attr))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/GCN_study/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/GCN_study/lib/python3.9/site-packages/torch_geometric/nn/conv/cheb_conv.py:148\u001b[0m, in \u001b[0;36mChebConv.forward\u001b[0;34m(self, x, edge_index, edge_weight, batch, lambda_max)\u001b[0m\n\u001b[1;32m    146\u001b[0m Tx_0 \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    147\u001b[0m Tx_1 \u001b[38;5;241m=\u001b[39m x  \u001b[38;5;66;03m# Dummy.\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlins\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTx_0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, norm: Tensor)\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlins) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/GCN_study/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/GCN_study/lib/python3.9/site-packages/torch_geometric/nn/dense/linear.py:118\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m        x (Tensor): The features.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (190x190 and 36100x128)"
     ]
    }
   ],
   "source": [
    "\n",
    "def GCN_train(loader):\n",
    "    model.train()\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = func.cross_entropy(output, data.y)\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "def GCN_test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    pred = []\n",
    "    label = []\n",
    "    loss_all = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        loss = func.cross_entropy(output, data.y)\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        pred.append(func.softmax(output, dim=1).max(dim=1)[1])\n",
    "        label.append(data.y)\n",
    "\n",
    "    y_pred = torch.cat(pred, dim=0).cpu().detach().numpy()\n",
    "    y_true = torch.cat(label, dim=0).cpu().detach().numpy()\n",
    "    tn, fp, fn, tp = confusion_matrix(y_pred, y_true).ravel()\n",
    "    epoch_sen = tp / (tp + fn)\n",
    "    epoch_spe = tn / (tn + fp)\n",
    "    epoch_acc = (tn + tp) / (tn + tp + fn + fp)\n",
    "    return epoch_sen, epoch_spe, epoch_acc, loss_all / len(val_dataset)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(36100, 2, 3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "   \n",
    "min_v_loss = np.inf    \n",
    "for epoch in range(50):\n",
    "    t_loss = GCN_train(train_data)\n",
    "    test_sen, test_spe, test_acc, _ = GCN_test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b6444e-5baa-40cb-ad80-7024aa6ef874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e4c4a-d876-4d09-b608-39b7a3788660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
