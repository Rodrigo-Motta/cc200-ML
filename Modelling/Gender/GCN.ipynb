{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ec5c0a04-5483-4caa-a068-9e06fc2c63c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(rc={'image.cmap': 'coolwarm'})\n",
    "\n",
    "#from numba import jit,prange\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cca6cf18-d292-4c44-a147-65c77b9aba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(size, corr):\n",
    "    corr_matrix = np.zeros((size,size))\n",
    "    cont = 0\n",
    "\n",
    "    for i in range(size):\n",
    "        for j in range(i, size):\n",
    "            if i == j:\n",
    "                corr_matrix[i,j] = 0#float('nan')\n",
    "\n",
    "\n",
    "            else:\n",
    "                corr_matrix[i,j] = corr[cont]\n",
    "                corr_matrix[j,i] = corr[cont]\n",
    "                cont += 1 \n",
    "    return corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "43d0bc9e-d442-479e-a12c-e6e068f5b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(fisher):\n",
    "    if fisher == True:\n",
    "        df = pd.read_csv(r'/Users/rodrigo/Post-Grad/CC400/corr_matrices_fisher200.csv',index_col=['Institution','Subject'])\n",
    "        phenotypic = pd.read_csv(r'/Users/rodrigo/Post-Grad/CC400/phenotypic200.csv',index_col=['Institution','Subject'])\n",
    "    else:\n",
    "        df = pd.read_csv(r'/Users/rodrigo/Post-Grad/CC400/corr_matrices200.csv',index_col=['Institution','Subject','Run'])\n",
    "        phenotypic = pd.read_csv(r'/Users/rodrigo/Post-Grad/CC400/phenotypic200.csv',index_col=['Institution','Subject'])\n",
    "    return df,phenotypic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "12920c28-3874-464b-acd6-2da7c2303fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, phenotypic = import_data(fisher=True)\n",
    "df = df.join(pd.DataFrame(phenotypic.Age), how='left')\n",
    "df = df.join(pd.DataFrame(phenotypic['ADHD Measure']), how='left')\n",
    "df = df.join(pd.DataFrame(phenotypic['Gender']), how='left')\n",
    "\n",
    "#df = ((df.reset_index()).drop(columns=['Institution', 'Subject','Run'])).dropna(subset=[str(x) for x in range(0,61425)])\n",
    "df = ((df.reset_index()).drop(columns=['Institution', 'Subject'])).dropna(subset=[str(x) for x in range(0,17954)])\n",
    "df = df.dropna(axis=0, subset=['Gender'])\n",
    "y = (df.Gender).apply(lambda x: int(x))\n",
    "X = df.iloc[:,:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4aa9f44a-0853-4384-b984-6b46a357cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4ae6545f-ae73-4e9a-9521-c84e193aad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "\n",
    "for i in range((X_train.shape[0])):\n",
    "    adj = correlation_matrix(190,X_train.iloc[i,:].values)\n",
    "    np.fill_diagonal(adj,0)\n",
    "    adj = torch.from_numpy(adj).float()\n",
    "    edge_index, edge_attr = dense_to_sparse(adj)\n",
    "    train_data.append(Data(x=adj, edge_index=edge_index, edge_attr=edge_attr.reshape(len(edge_attr), 1),\n",
    "                           y=torch.tensor(int(y_train.iloc[i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "15423ce4-45b9-42d4-8a3c-94e39c72ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "\n",
    "for i in range((X_test.shape[0])):\n",
    "    adj = correlation_matrix(190,X_test.iloc[i,:].values)\n",
    "    np.fill_diagonal(adj,1)\n",
    "    adj = torch.from_numpy(adj).float()\n",
    "    edge_index, edge_attr = dense_to_sparse(adj)\n",
    "    test_data.append(Data(x=adj, edge_index=edge_index, edge_attr=edge_attr.reshape(len(edge_attr), 1),\n",
    "                          y=torch.tensor(int(y_test.iloc[i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e0c59bc2-b6f7-45a1-96b9-c9c891e6f301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[190, 190], edge_index=[2, 36100], edge_attr=[36100, 1], y=0)\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "49767bb6-2c5f-4180-9165-f9d046ad7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_data, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "07d45df4-28f8-4a4f-9b24-0449e9c2b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for data in train_loader:\n",
    "    #print(batch)\n",
    "    #print('num_nodes',batch.num_nodes)\n",
    "    #print(batch.x.shape)\n",
    "    #print(data.edge_index.shape)\n",
    "    #print(data.batch)\n",
    "    #print('num_graphs', batch.num_graphs)\n",
    "    # data = data.to(device)\n",
    "    # optimizer.zero_grad()\n",
    "    # out = model(data.x, data.edge_index, data.batch)\n",
    "    # loss = F.cross_entropy(out, data.y)\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    # total_loss += float(loss) * data.num_graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c89df864-e874-4177-9a0c-094ddd99da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as func\n",
    "from torch_geometric.nn import ChebConv, GCNConv, global_mean_pool\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"GCN model(network architecture can be modified)\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_features,\n",
    "                 num_classes,\n",
    "                 k_order,\n",
    "                 dropout=.1):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.p = dropout\n",
    "        \n",
    "        self.conv1 = GCNConv(int(num_features), 64)\n",
    "        self.conv2 = GCNConv(64, 16)\n",
    "\n",
    "        #self.conv1 = ChebConv(int(num_features), 32, K=k_order)\n",
    "        #self.conv2 = ChebConv(32, 16, K=k_order)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(16, int(num_classes))\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        batch = data.batch\n",
    "        \n",
    "        x = func.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = func.dropout(x, p=self.p, training=self.training)\n",
    "        x = func.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = func.dropout(x, p=self.p, training=self.training)\n",
    "        \n",
    "        x = self.pool(x, batch)\n",
    "        x = self.lin1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0663c-15ee-45f9-970a-3a4e53041501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   2%| | 1/41 [00:00<00:12,  3.32it/s, loss=tensor(nan, grad_fn=<Nl"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   7%| | 3/41 [00:00<00:08,  4.70it/s, loss=tensor(nan, grad_fn=<Nl"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:  12%| | 5/41 [00:01<00:06,  5.18it/s, loss=tensor(nan, grad_fn=<Nl"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:  17%|▏| 7/41 [00:01<00:06,  5.19it/s, loss=tensor(nan, grad_fn=<Nl"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:  22%|▏| 9/41 [00:01<00:06,  5.20it/s, loss=tensor(nan, grad_fn=<Nl"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:  27%|▎| 11/41 [00:02<00:05,  5.38it/s, loss=tensor(nan, grad_fn=<N"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:  32%|▎| 13/41 [00:02<00:05,  5.13it/s, loss=tensor(nan, grad_fn=<N"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:  34%|▎| 14/41 [00:02<00:05,  5.16it/s, loss=tensor(nan, grad_fn=<N"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:  37%|▎| 15/41 [00:02<00:05,  4.90it/s, loss=tensor(nan, grad_fn=<N"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:  39%|▍| 16/41 [00:03<00:05,  4.87it/s, loss=tensor(nan, grad_fn=<N"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:  44%|▍| 18/41 [00:03<00:04,  5.08it/s, loss=tensor(nan, grad_fn=<N"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:  46%|▍| 19/41 [00:03<00:04,  5.00it/s, loss=tensor(nan, grad_fn=<N\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,NUM_EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     61\u001b[0m     loop \u001b[38;5;241m=\u001b[39m tqdm(train_loader)\n\u001b[0;32m---> 62\u001b[0m     t_loss \u001b[38;5;241m=\u001b[39m \u001b[43mGCN_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     test_sen, test_spe, test_acc, _ \u001b[38;5;241m=\u001b[39m GCN_test(test_loader)\n",
      "Cell \u001b[0;32mIn[137], line 19\u001b[0m, in \u001b[0;36mGCN_train\u001b[0;34m(loader, loop)\u001b[0m\n\u001b[1;32m     17\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mcross_entropy(output, y\u001b[38;5;241m.\u001b[39my)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/GCN_study/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[136], line 33\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m x, edge_index, edge_attr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[1;32m     31\u001b[0m batch \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mbatch\n\u001b[0;32m---> 33\u001b[0m x \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index, edge_attr))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/GCN_study/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/GCN_study/lib/python3.9/site-packages/torch_geometric/nn/conv/gcn_conv.py:197\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    194\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m                     \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/GCN_study/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:374\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    373\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 374\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    376\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/GCN_study/lib/python3.9/site-packages/torch_geometric/nn/conv/gcn_conv.py:206\u001b[0m, in \u001b[0;36mGCNConv.message\u001b[0;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor, edge_weight: OptTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_j \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_j\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def GCN_train(loader, loop):\n",
    "    model.train()\n",
    "\n",
    "    loss_all = 0\n",
    "    \n",
    "    #for data in loader:\n",
    "        # data = data.to(device)\n",
    "        # optimizer.zero_grad()\n",
    "        # output = model(data)\n",
    "        # loss = func.cross_entropy(output, data.y)\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        # loss_all += data.num_graphs * loss.item()\n",
    "        # #optimizer.step()\n",
    "        \n",
    "    for (x, y) in enumerate(loop):\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(y)\n",
    "        print(output)\n",
    "        loss = func.cross_entropy(output, y.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_all += y.num_graphs * loss.item()\n",
    "        loop.set_description(f\"Epoch [{epoch}/{NUM_EPOCHS}]\")\n",
    "        loop.set_postfix(loss=loss)\n",
    "        #optimizer.step()\n",
    "    return loss_all / len(train_data)\n",
    "\n",
    "\n",
    "def GCN_test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    pred = []\n",
    "    label = []\n",
    "    loss_all = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        loss = func.cross_entropy(output, data.y)\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        pred.append(func.softmax(output, dim=1).max(dim=1)[1])\n",
    "        label.append(data.y)\n",
    "\n",
    "    y_pred = torch.cat(pred, dim=0).cpu().detach().numpy()\n",
    "    y_true = torch.cat(label, dim=0).cpu().detach().numpy()\n",
    "    tn, fp, fn, tp = confusion_matrix(y_pred, y_true).ravel()\n",
    "    epoch_sen = tp / (tp + fn)\n",
    "    epoch_spe = tn / (tn + fp)\n",
    "    epoch_acc = (tn + tp) / (tn + tp + fn + fp)\n",
    "    return epoch_sen, epoch_spe, epoch_acc, loss_all / len(test_data)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(190, 2, 3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "   \n",
    "min_v_loss = np.inf  \n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "for epoch in range(1,NUM_EPOCHS + 1):\n",
    "    loop = tqdm(train_loader)\n",
    "    t_loss = GCN_train(train_loader,loop)\n",
    "    test_sen, test_spe, test_acc, _ = GCN_test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf24ce-44df-402e-bbb4-2411db756c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for y in test_loader:\n",
    "    y_pred.append(model(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c408d625-117e-4b14-a218-a2930e834990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[nan, nan]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[nan, nan]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[nan, nan]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[nan, nan]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[nan, nan]], grad_fn=<AddmmBackward0>)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a4ce77ec-c52e-4b49-9db9-841ddf035dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37719298245614036"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "74faf25f-0203-454e-b8be-4def854f719c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a0593cfa-9c26-4355-96d9-2aaead1b33a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37719298245614036"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_spe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "25535c7c-2375-4e1c-ad32-7dd02f4c351f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e20156-6534-4ca8-ad73-41aa03976401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
